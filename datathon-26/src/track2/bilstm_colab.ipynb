{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37461319",
   "metadata": {},
   "source": [
    "# BiLSTM + GloVe — Datathon Track 2 (Run 2)\n",
    "**A100 GPU. Key fixes vs Run 1:**\n",
    "- `EPOCHS=30`, `PATIENCE=5` — model was still improving at epoch 15\n",
    "- `POS_WEIGHT_CAP=10` — fixes threshold stuck at 0.90–0.94\n",
    "- `HIDDEN_DIM=512` — doubles model capacity\n",
    "\n",
    "Drive folder already mounted from Run 1 — just re-run Cell 3 onward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e68fcc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch: 2.10.0+cu128\n",
      "CUDA : True\n",
      "GPU  : NVIDIA A100-SXM4-80GB\n",
      "VRAM : 85.1 GB\n"
     ]
    }
   ],
   "source": [
    "# Cell 1 — Check GPU\n",
    "import torch\n",
    "print('torch:', torch.__version__)\n",
    "print('CUDA :', torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print('GPU  :', torch.cuda.get_device_name(0))\n",
    "    print('VRAM :', round(torch.cuda.get_device_properties(0).total_memory/1e9,1), 'GB')\n",
    "else:\n",
    "    raise RuntimeError('No GPU — Runtime > Change runtime type > A100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df24111e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deps ready.\n"
     ]
    }
   ],
   "source": [
    "# Cell 2 — Deps\n",
    "import subprocess, sys\n",
    "subprocess.run([sys.executable, '-m', 'pip', 'install', '-q',\n",
    "                'scikit-learn', 'pandas', 'numpy'])\n",
    "print('Deps ready.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98464668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "  OK  train.csv  (12.5 MB)\n",
      "  OK  val.csv  (2.7 MB)\n",
      "  OK  label_list.txt  (0.0 MB)\n",
      "All data files ready.\n"
     ]
    }
   ],
   "source": [
    "# Cell 3 — Mount Google Drive and copy data files\n",
    "from google.colab import drive\n",
    "import shutil, os\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "DRIVE_FOLDER = '/content/drive/MyDrive/datathon'   # <-- edit if needed\n",
    "\n",
    "for fname in ['train.csv', 'val.csv', 'label_list.txt']:\n",
    "    src = os.path.join(DRIVE_FOLDER, fname)\n",
    "    if os.path.exists(src):\n",
    "        shutil.copy(src, fname)\n",
    "        print(f'  OK  {fname}  ({os.path.getsize(fname)/1e6:.1f} MB)')\n",
    "    else:\n",
    "        print(f'  MISSING: {src}')\n",
    "\n",
    "missing = [f for f in ['train.csv', 'val.csv', 'label_list.txt']\n",
    "           if not os.path.exists(f)]\n",
    "if missing:\n",
    "    raise FileNotFoundError(f'Missing: {missing} — check DRIVE_FOLDER above')\n",
    "print('All data files ready.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "358ba103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GloVe already present, skipping download.\n",
      "Size: 1.04 GB\n"
     ]
    }
   ],
   "source": [
    "# Cell 4 — GloVe (skips download if already present from Run 1)\n",
    "import os\n",
    "os.makedirs('data/glove', exist_ok=True)\n",
    "glove_path = 'data/glove/glove.6B.300d.txt'\n",
    "\n",
    "if not os.path.exists(glove_path):\n",
    "    print('Downloading glove.6B.zip (~820 MB) ...')\n",
    "    os.system('wget -q --show-progress https://nlp.stanford.edu/data/glove.6B.zip '\n",
    "              '-O data/glove/glove.6B.zip')\n",
    "    os.system(\"unzip -j data/glove/glove.6B.zip 'glove.6B.300d.txt' -d data/glove/\")\n",
    "    os.remove('data/glove/glove.6B.zip')\n",
    "    print('Done.')\n",
    "else:\n",
    "    print('GloVe already present, skipping download.')\n",
    "print(f'Size: {os.path.getsize(glove_path)/1e9:.2f} GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "728ccd50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Train 15,104  Val 3,236  Labels 116\n",
      "Building vocab ...\n",
      "Loading GloVe ...\n",
      "  25,825/50,000 words matched\n",
      "Params: 24,752,692\n",
      "\n",
      "----------------------------------------------------------\n",
      "   Ep      loss   Micro F1    thr\n",
      "----------------------------------------------------------\n",
      "    1    0.1599     0.3995   0.43 ★\n",
      "    2    0.1320     0.3062   0.37\n",
      "    3    0.1078     0.4947   0.62 ★\n",
      "    4    0.0891     0.5926   0.63 ★\n",
      "    5    0.0679     0.6681   0.71 ★\n",
      "    6    0.0552     0.6926   0.80 ★\n",
      "    7    0.0466     0.7244   0.80 ★\n",
      "    8    0.0399     0.7344   0.80 ★\n",
      "    9    0.0339     0.7457   0.78 ★\n",
      "   10    0.0285     0.7719   0.81 ★\n",
      "   11    0.0243     0.7549   0.81\n",
      "   12    0.0217     0.7765   0.78 ★\n",
      "   13    0.0187     0.7798   0.83 ★\n",
      "   14    0.0169     0.7804   0.83 ★\n",
      "   15    0.0158     0.7915   0.81 ★\n",
      "   16    0.0144     0.7931   0.77 ★\n",
      "   17    0.0136     0.7939   0.80 ★\n",
      "   18    0.0118     0.7956   0.78 ★\n",
      "   19    0.0107     0.7941   0.76\n",
      "   20    0.0096     0.8003   0.76 ★\n",
      "   21    0.0088     0.8011   0.86 ★\n",
      "   22    0.0083     0.7977   0.82\n",
      "   23    0.0074     0.8032   0.73 ★\n",
      "   24    0.0070     0.8046   0.87 ★\n",
      "   25    0.0061     0.8057   0.86 ★\n",
      "   26    0.0057     0.8018   0.90\n",
      "   27    0.0051     0.8098   0.78 ★\n",
      "   28    0.0051     0.8055   0.76\n",
      "   29    0.0048     0.8070   0.71\n",
      "   30    0.0044     0.8002   0.71\n",
      "----------------------------------------------------------\n",
      "Best val Micro F1: 0.8098  @ thr=0.78\n",
      "Artifacts saved to model/\n"
     ]
    }
   ],
   "source": [
    "# Cell 5 — Train BiLSTM (Run 2 — tuned hyperparameters)\n",
    "import os, json, pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# ── Config (key changes from Run 1 marked with <--) ──────────────────────────\n",
    "TRAIN_PATH      = 'train.csv'\n",
    "VAL_PATH        = 'val.csv'\n",
    "LABEL_LIST_PATH = 'label_list.txt'\n",
    "GLOVE_PATH      = 'data/glove/glove.6B.300d.txt'\n",
    "MODEL_DIR       = 'model/'\n",
    "VOCAB_SIZE      = 50_000\n",
    "MAX_LEN         = 300\n",
    "EMBED_DIM       = 300\n",
    "HIDDEN_DIM      = 512      # <-- doubled (was 256)\n",
    "NUM_LAYERS      = 2\n",
    "DROPOUT         = 0.3\n",
    "BATCH_SIZE      = 128\n",
    "EPOCHS          = 30       # <-- more epochs (was 15, model wasn't converged)\n",
    "LR              = 1e-3\n",
    "PATIENCE        = 5        # <-- more patience (was 3)\n",
    "POS_WEIGHT_CAP  = 10.0     # <-- lower cap (was 50) — fixes threshold stuck at 0.90+\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Device: {DEVICE}')\n",
    "\n",
    "# Helpers\n",
    "def load_label_list(path):\n",
    "    labels = [ln.strip().lower() for ln in open(path, encoding='utf-8') if ln.strip()]\n",
    "    if 'none' not in labels: labels.append('none')\n",
    "    seen = set()\n",
    "    return [x for x in labels if not (x in seen or seen.add(x))]\n",
    "\n",
    "def parse_topics(x, known=None):\n",
    "    x = (x or 'none').strip().lower()\n",
    "    parts = [t.strip() for t in x.split('|') if t.strip()]\n",
    "    if known: parts = [t for t in parts if t in known]\n",
    "    return parts if parts else ['none']\n",
    "\n",
    "def combine_text(df):\n",
    "    return (df['title'].fillna('').astype(str) + '. ' +\n",
    "            df['text'].fillna('').astype(str)).tolist()\n",
    "\n",
    "def build_vocab(texts, max_vocab):\n",
    "    from collections import Counter\n",
    "    c = Counter()\n",
    "    for t in texts: c.update(t.lower().split())\n",
    "    v = {'<PAD>': 0, '<UNK>': 1}\n",
    "    for w, _ in c.most_common(max_vocab - 2): v[w] = len(v)\n",
    "    return v\n",
    "\n",
    "def texts_to_sequences(texts, vocab, max_len):\n",
    "    UNK = vocab.get('<UNK>', 1)\n",
    "    seqs = []\n",
    "    for t in texts:\n",
    "        ids = [vocab.get(tok, UNK) for tok in t.lower().split()[:max_len]]\n",
    "        ids += [0] * (max_len - len(ids))\n",
    "        seqs.append(ids)\n",
    "    return np.array(seqs, dtype=np.int64)\n",
    "\n",
    "def load_glove(path, vocab, embed_dim):\n",
    "    print('Loading GloVe ...')\n",
    "    rng = np.random.default_rng(42)\n",
    "    mat = rng.uniform(-0.05, 0.05, (len(vocab), embed_dim)).astype(np.float32)\n",
    "    mat[0] = 0.0\n",
    "    found = 0\n",
    "    with open(path, encoding='utf-8') as fh:\n",
    "        for line in fh:\n",
    "            p = line.rstrip().split(' ')\n",
    "            if len(p) != embed_dim + 1: continue\n",
    "            if p[0] in vocab:\n",
    "                mat[vocab[p[0]]] = np.array(p[1:], dtype=np.float32)\n",
    "                found += 1\n",
    "    print(f'  {found:,}/{len(vocab):,} words matched')\n",
    "    return mat\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = torch.from_numpy(X); self.Y = torch.from_numpy(Y)\n",
    "    def __len__(self): return len(self.X)\n",
    "    def __getitem__(self, i): return self.X[i], self.Y[i]\n",
    "\n",
    "class BiLSTMClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, embed_matrix,\n",
    "                 hidden_dim, num_layers, num_labels, dropout):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        self.embedding.weight = nn.Parameter(\n",
    "            torch.tensor(embed_matrix, dtype=torch.float32))\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, num_layers=num_layers,\n",
    "                            bidirectional=True, batch_first=True,\n",
    "                            dropout=dropout if num_layers > 1 else 0.0)\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        self.fc   = nn.Linear(hidden_dim * 2, num_labels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mask    = (x != 0).float()\n",
    "        lengths = mask.sum(1, keepdim=True).clamp(min=1)\n",
    "        emb     = self.drop(self.embedding(x))\n",
    "        out, _  = self.lstm(emb)\n",
    "        pooled  = (out * mask.unsqueeze(-1)).sum(1) / lengths\n",
    "        return self.fc(self.drop(pooled))\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_val_probs(model, loader, device):\n",
    "    model.eval()\n",
    "    P, L = [], []\n",
    "    for X, Y in loader:\n",
    "        P.append(torch.sigmoid(model(X.to(device))).cpu().numpy())\n",
    "        L.append(Y.numpy())\n",
    "    return np.vstack(P), np.vstack(L)\n",
    "\n",
    "def sweep_threshold(probs, labels):\n",
    "    best_t, best_m = 0.5, -1.0\n",
    "    for t in np.arange(0.10, 0.95, 0.01):   # wider sweep — catches low-prob models\n",
    "        m = f1_score(labels, (probs >= t).astype(int),\n",
    "                     average='micro', zero_division=0)\n",
    "        if m > best_m: best_m, best_t = m, float(t)\n",
    "    return best_t, best_m\n",
    "\n",
    "# Run\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "train_df   = pd.read_csv(TRAIN_PATH, dtype=str).fillna('')\n",
    "val_df     = pd.read_csv(VAL_PATH,   dtype=str).fillna('')\n",
    "labels     = load_label_list(LABEL_LIST_PATH)\n",
    "known      = set(labels)\n",
    "num_labels = len(labels)\n",
    "print(f'Train {len(train_df):,}  Val {len(val_df):,}  Labels {num_labels}')\n",
    "\n",
    "mlb     = MultiLabelBinarizer(classes=labels)\n",
    "Y_train = mlb.fit_transform(\n",
    "    train_df['topics'].apply(lambda x: parse_topics(x, known))).astype(np.float32)\n",
    "Y_val   = mlb.transform(\n",
    "    val_df['topics'].apply(lambda x: parse_topics(x, known))).astype(np.float32)\n",
    "\n",
    "train_texts = combine_text(train_df)\n",
    "val_texts   = combine_text(val_df)\n",
    "print('Building vocab ...')\n",
    "vocab        = build_vocab(train_texts, VOCAB_SIZE)\n",
    "X_train      = texts_to_sequences(train_texts, vocab, MAX_LEN)\n",
    "X_val        = texts_to_sequences(val_texts,   vocab, MAX_LEN)\n",
    "embed_matrix = load_glove(GLOVE_PATH, vocab, EMBED_DIM)\n",
    "\n",
    "train_loader = DataLoader(TextDataset(X_train, Y_train), batch_size=BATCH_SIZE,\n",
    "                          shuffle=True,  num_workers=2, pin_memory=True)\n",
    "val_loader   = DataLoader(TextDataset(X_val,   Y_val),   batch_size=BATCH_SIZE*4,\n",
    "                          shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "model = BiLSTMClassifier(len(vocab), EMBED_DIM, embed_matrix,\n",
    "                         HIDDEN_DIM, NUM_LAYERS, num_labels, DROPOUT).to(DEVICE)\n",
    "print(f'Params: {sum(p.numel() for p in model.parameters()):,}')\n",
    "\n",
    "pos_counts = Y_train.sum(0).clip(min=1)\n",
    "pos_weight = torch.tensor(\n",
    "    np.clip((len(Y_train) - pos_counts) / pos_counts, None, POS_WEIGHT_CAP),\n",
    "    dtype=torch.float32).to(DEVICE)\n",
    "criterion  = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "optimizer  = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "scheduler  = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='max', factor=0.5, patience=2)\n",
    "\n",
    "best_micro, best_thr, patience_ctr = -1.0, 0.5, 0\n",
    "print(f'\\n{\"-\"*58}')\n",
    "print(f'  {\"Ep\":>3}  {\"loss\":>8}  {\"Micro F1\":>9}  {\"thr\":>5}')\n",
    "print(f'{\"-\"*58}')\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    model.train()\n",
    "    total, n = 0.0, 0\n",
    "    for X, Y in train_loader:\n",
    "        X, Y = X.to(DEVICE), Y.to(DEVICE)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss = criterion(model(X), Y)\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        total += loss.item(); n += 1\n",
    "\n",
    "    probs, lbls = get_val_probs(model, val_loader, DEVICE)\n",
    "    thr, micro  = sweep_threshold(probs, lbls)\n",
    "    scheduler.step(micro)\n",
    "\n",
    "    star = ' ★' if micro > best_micro + 1e-5 else ''\n",
    "    print(f'  {epoch:3d}  {total/n:8.4f}  {micro:9.4f}  {thr:5.2f}{star}', flush=True)\n",
    "\n",
    "    if micro > best_micro + 1e-5:\n",
    "        best_micro, best_thr = micro, thr\n",
    "        torch.save(model.state_dict(), os.path.join(MODEL_DIR, 'bilstm.pt'))\n",
    "        patience_ctr = 0\n",
    "    else:\n",
    "        patience_ctr += 1\n",
    "        if patience_ctr >= PATIENCE:\n",
    "            print(f'  Early stopping at epoch {epoch}')\n",
    "            break\n",
    "\n",
    "print(f'{\"-\"*58}')\n",
    "print(f'Best val Micro F1: {best_micro:.4f}  @ thr={best_thr:.2f}')\n",
    "\n",
    "with open(os.path.join(MODEL_DIR, 'vocab.pkl'), 'wb') as f: pickle.dump(vocab, f)\n",
    "with open(os.path.join(MODEL_DIR, 'mlb.pkl'),   'wb') as f: pickle.dump(mlb,   f)\n",
    "meta = dict(best_threshold=best_thr, num_labels=num_labels,\n",
    "            max_len=MAX_LEN, embed_dim=EMBED_DIM, hidden_dim=HIDDEN_DIM,\n",
    "            num_layers=NUM_LAYERS, dropout=DROPOUT, vocab_size=len(vocab),\n",
    "            val_micro_f1=round(best_micro,4), labels=labels)\n",
    "with open(os.path.join(MODEL_DIR, 'meta_bilstm.json'), 'w') as f:\n",
    "    json.dump(meta, f, indent=2)\n",
    "print('Artifacts saved to model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3674ebc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  bilstm.pt  (99.0 MB)\n",
      "  vocab.pkl  (0.7 MB)\n",
      "  mlb.pkl  (0.0 MB)\n",
      "  meta_bilstm.json  (0.0 MB)\n",
      "\n",
      "Saved to Google Drive: /content/drive/MyDrive/datathon/bilstm_model.zip\n",
      "Download from Drive, unzip locally: unzip bilstm_model.zip -d model/\n"
     ]
    }
   ],
   "source": [
    "# Cell 6 — Zip and save model artifacts to Google Drive\n",
    "import zipfile, shutil, os\n",
    "\n",
    "zip_path = 'bilstm_model.zip'\n",
    "with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zf:\n",
    "    for fname in ['bilstm.pt', 'vocab.pkl', 'mlb.pkl', 'meta_bilstm.json']:\n",
    "        fpath = os.path.join('model', fname)\n",
    "        zf.write(fpath, fname)\n",
    "        print(f'  {fname}  ({os.path.getsize(fpath)/1e6:.1f} MB)')\n",
    "\n",
    "drive_out = os.path.join(DRIVE_FOLDER, zip_path)\n",
    "shutil.copy(zip_path, drive_out)\n",
    "print(f'\\nSaved to Google Drive: {drive_out}')\n",
    "print('Download from Drive, unzip locally: unzip bilstm_model.zip -d model/')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
